{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from os import environ\n",
    "from importlib import reload\n",
    "import tensorflow as tf\n",
    "\n",
    "# user defined function to change keras backend\n",
    "def set_keras_backend(backend):\n",
    "    if K.backend() != backend:\n",
    "       environ['KERAS_BACKEND'] = backend\n",
    "       reload(K)\n",
    "       assert K.backend() == backend\n",
    "\n",
    "# call the function with \"tensorflow\"\n",
    "set_keras_backend(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pylab as pylab\n",
    "import cv2\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "print(keras.backend.backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>377.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17814.jpg</td>\n",
       "      <td>YOUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21283.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16496.jpg</td>\n",
       "      <td>YOUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4487.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID   Class\n",
       "0    377.jpg  MIDDLE\n",
       "1  17814.jpg   YOUNG\n",
       "2  21283.jpg  MIDDLE\n",
       "3  16496.jpg   YOUNG\n",
       "4   4487.jpg  MIDDLE"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv('train.csv')\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\\23790.jpg\n",
      "23790.jpg\n"
     ]
    }
   ],
   "source": [
    "img_name = rng.choice(train_csv.ID)\n",
    "filepath = os.path.join('Train', img_name)\n",
    "print(filepath)\n",
    "print(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = []\n",
    "for img_name in train_csv.ID:\n",
    "    image_path = os.path.join('Train',img_name)\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (32,32))\n",
    "    img = np.array(img, dtype = 'float32')\n",
    "    img_array.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.stack(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_csv.Class)\n",
    "encoded_labels = encoder.transform(train_csv.Class)\n",
    "train_y = np_utils.to_categorical(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten()) #Flattening the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Adding layers\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling model\n",
    "classifier.compile( optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.8243 - acc: 0.6250\n",
      "Epoch 2/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.7010 - acc: 0.6937\n",
      "Epoch 3/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.6386 - acc: 0.7233: 1s - los\n",
      "Epoch 4/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.5782 - acc: 0.7523\n",
      "Epoch 5/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.5197 - acc: 0.7804\n",
      "Epoch 6/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.4708 - acc: 0.8075\n",
      "Epoch 7/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.4094 - acc: 0.8319\n",
      "Epoch 8/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.3631 - acc: 0.8539\n",
      "Epoch 9/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.3120 - acc: 0.8736\n",
      "Epoch 10/30\n",
      "19906/19906 [==============================] - 50s 2ms/step - loss: 0.2714 - acc: 0.8915\n",
      "Epoch 11/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.2359 - acc: 0.9071\n",
      "Epoch 12/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.2108 - acc: 0.9176\n",
      "Epoch 13/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.1800 - acc: 0.9303\n",
      "Epoch 14/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.1551 - acc: 0.9412\n",
      "Epoch 15/30\n",
      "19906/19906 [==============================] - 54s 3ms/step - loss: 0.1474 - acc: 0.9449\n",
      "Epoch 16/30\n",
      "19906/19906 [==============================] - 53s 3ms/step - loss: 0.1225 - acc: 0.9547\n",
      "Epoch 17/30\n",
      "19906/19906 [==============================] - 53s 3ms/step - loss: 0.1097 - acc: 0.9596\n",
      "Epoch 18/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.1082 - acc: 0.9597\n",
      "Epoch 19/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.0926 - acc: 0.9663\n",
      "Epoch 20/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.0915 - acc: 0.9666\n",
      "Epoch 21/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.0756 - acc: 0.9722\n",
      "Epoch 22/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.0702 - acc: 0.9750\n",
      "Epoch 23/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.0815 - acc: 0.9693\n",
      "Epoch 24/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.0593 - acc: 0.9789\n",
      "Epoch 25/30\n",
      "19906/19906 [==============================] - 53s 3ms/step - loss: 0.0587 - acc: 0.9795\n",
      "Epoch 26/30\n",
      "19906/19906 [==============================] - 54s 3ms/step - loss: 0.0601 - acc: 0.9793\n",
      "Epoch 27/30\n",
      "19906/19906 [==============================] - 55s 3ms/step - loss: 0.0609 - acc: 0.9786\n",
      "Epoch 28/30\n",
      "19906/19906 [==============================] - 54s 3ms/step - loss: 0.0583 - acc: 0.9801\n",
      "Epoch 29/30\n",
      "19906/19906 [==============================] - 54s 3ms/step - loss: 0.0557 - acc: 0.9810\n",
      "Epoch 30/30\n",
      "19906/19906 [==============================] - 54s 3ms/step - loss: 0.0553 - acc: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b4f1449b70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Model\n",
    "classifier.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19906/19906 [==============================] - 18s 880us/step\n"
     ]
    }
   ],
   "source": [
    "score = classifier.evaluate(train_x, train_y, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  99.12086807997589\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score[1])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25321.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>989.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19277.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13093.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5367.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID\n",
       "0  25321.jpg\n",
       "1    989.jpg\n",
       "2  19277.jpg\n",
       "3  13093.jpg\n",
       "4   5367.jpg"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Test Data\n",
    "test = pd.read_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\\18879.jpg\n",
      "18879.jpg\n"
     ]
    }
   ],
   "source": [
    "img_name_test = rng.choice(test.ID)\n",
    "filepath = os.path.join('Test', img_name_test)\n",
    "print(filepath)\n",
    "print(img_name_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = []\n",
    "for img_name in test.ID:\n",
    "    image_path = os.path.join('Test',img_name)\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (32,32))\n",
    "    img = np.array(img, dtype = 'float32')\n",
    "    img_array.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.stack(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.predict_classes(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, ..., 0, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6636"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "pred = encoder.inverse_transform(pred)\n",
    "\n",
    "test['Class'] = pred\n",
    "test.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  import sys\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: MIDDLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "i = random.choice(test.index)\n",
    "img_name = test.ID[i]\n",
    "img_path = os.path.join('Test', img_name)\n",
    "img = imread(img_path).astype('float32')\n",
    "#imshow(imresize(img, (128, 128)))\n",
    "plt.imshow(imresize(img, (128, 128)))\n",
    "plt.show()\n",
    "pred = classifier.predict_classes(test_x)\n",
    "print('Predicted:', encoder.inverse_transform(pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU, PReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LeakyRelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.8273 - acc: 0.6286\n",
      "Epoch 2/10\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.7106 - acc: 0.6859\n",
      "Epoch 3/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.6444 - acc: 0.7221\n",
      "Epoch 4/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.5880 - acc: 0.7502\n",
      "Epoch 5/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.5352 - acc: 0.7814\n",
      "Epoch 6/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.4853 - acc: 0.7995\n",
      "Epoch 7/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.4387 - acc: 0.8216\n",
      "Epoch 8/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.4003 - acc: 0.8372\n",
      "Epoch 9/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.3551 - acc: 0.8567\n",
      "Epoch 10/10\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.3219 - acc: 0.8737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b487949390>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_1 = Sequential()\n",
    "\n",
    "classifier_1.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))\n",
    "classifier_1.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_1.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer\n",
    "classifier_1.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_1.add(Flatten()) #Flattening the matrix\n",
    "classifier_1.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_1.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_1.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_1.add(Dense(output_dim = 3, activation = 'softmax'))\n",
    "classifier_1.add(LeakyReLU(alpha=.1))\n",
    "classifier_1.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "epochs = 10\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance\n",
    "classifier_1.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19906/19906 [==============================] - 13s 675us/step\n"
     ]
    }
   ],
   "source": [
    "score_1 = classifier_1.evaluate(train_x, train_y, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  90.20898221521944\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score_1[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"one\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.8287 - acc: 0.6244\n",
      "Epoch 2/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.7065 - acc: 0.6906\n",
      "Epoch 3/10\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.6406 - acc: 0.7214\n",
      "Epoch 4/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.5820 - acc: 0.7511\n",
      "Epoch 5/10\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.5336 - acc: 0.7776\n",
      "Epoch 6/10\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.4798 - acc: 0.8033\n",
      "Epoch 7/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.4335 - acc: 0.8217\n",
      "Epoch 8/10\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.3842 - acc: 0.8464\n",
      "Epoch 9/10\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.3365 - acc: 0.8673\n",
      "Epoch 10/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.2955 - acc: 0.8845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b487f652b0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_2 = Sequential()\n",
    "\n",
    "classifier_2.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))\n",
    "classifier_2.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_2.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer\n",
    "classifier_2.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_2.add(Flatten()) #Flattening the matrix\n",
    "classifier_2.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_2.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_2.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_2.add(Dense(output_dim = 3, activation = 'softmax'))\n",
    "act = keras.layers.advanced_activations.PReLU(init='one', weights=None)\n",
    "classifier_2.add(act)\n",
    "classifier_2.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "epochs = 10\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance\n",
    "classifier_2.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19906/19906 [==============================] - 14s 692us/step\n"
     ]
    }
   ],
   "source": [
    "score_2 = classifier_2.evaluate(train_x, train_y, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  91.19863358679865\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score_2[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does it effect the accuracy?\n",
    "**Ans:** As we can see, I have used 2 activation functions named LeakyRelu and PReLU, the accuracy of each is 90.1 and 91.1 respectively. PReLU is better than LeakyRelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does it effect how quickly the network plateaus?\n",
    "**Ans:** With each increase in epoch, loss is decreasing by almost 12% so to achieve a plateaus we need to increase the number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Squared_Hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"one\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.7623 - acc: 0.6193\n",
      "Epoch 2/10\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.7478 - acc: 0.6775\n",
      "Epoch 3/10\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.7421 - acc: 0.7009\n",
      "Epoch 4/10\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.7383 - acc: 0.7186\n",
      "Epoch 5/10\n",
      "19906/19906 [==============================] - 50s 2ms/step - loss: 0.7339 - acc: 0.7366\n",
      "Epoch 6/10\n",
      "19906/19906 [==============================] - 50s 2ms/step - loss: 0.7297 - acc: 0.7525\n",
      "Epoch 7/10\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.7255 - acc: 0.7761\n",
      "Epoch 8/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.7217 - acc: 0.7916\n",
      "Epoch 9/10\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.7184 - acc: 0.8041\n",
      "Epoch 10/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.7148 - acc: 0.8197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b488dfb5f8>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_3 = Sequential()\n",
    "\n",
    "classifier_3.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))\n",
    "classifier_3.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_3.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer\n",
    "classifier_3.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_3.add(Flatten()) #Flattening the matrix\n",
    "classifier_3.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_3.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_3.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_3.add(Dense(output_dim = 3, activation = 'softmax'))\n",
    "act = keras.layers.advanced_activations.PReLU(init='one', weights=None)\n",
    "classifier_3.add(act)\n",
    "classifier_3.compile(optimizer = 'adam',loss = 'squared_hinge', metrics = ['accuracy'])\n",
    "epochs = 10\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance\n",
    "classifier_3.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19906/19906 [==============================] - 14s 689us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7079131645760105, 0.8458756154761846]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_3 = classifier_3.evaluate(train_x, train_y, batch_size=128)\n",
    "score_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  84.58756154761846\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score_3[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"one\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.8194 - acc: 0.5428\n",
      "Epoch 2/10\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.8191 - acc: 0.5428\n",
      "Epoch 3/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.8191 - acc: 0.5428\n",
      "Epoch 4/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.8191 - acc: 0.5428\n",
      "Epoch 5/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.8191 - acc: 0.5428\n",
      "Epoch 6/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.8191 - acc: 0.5428\n",
      "Epoch 7/10\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.8191 - acc: 0.5428\n",
      "Epoch 8/10\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.8191 - acc: 0.5428\n",
      "Epoch 9/10\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.8191 - acc: 0.5428\n",
      "Epoch 10/10\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.8191 - acc: 0.5428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b4899c8f60>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_4 = Sequential()\n",
    "\n",
    "classifier_4.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))\n",
    "classifier_4.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_4.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer\n",
    "classifier_4.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_4.add(Flatten()) #Flattening the matrix\n",
    "classifier_4.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_4.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_4.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_4.add(Dense(output_dim = 3, activation = 'softmax'))\n",
    "act = keras.layers.advanced_activations.PReLU(init='one', weights=None)\n",
    "classifier_4.add(act)\n",
    "classifier_4.compile(optimizer = 'adam',loss = 'hinge', metrics = ['accuracy'])\n",
    "epochs = 10\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance\n",
    "classifier_4.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19906/19906 [==============================] - 13s 673us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8190829288261231, 0.5427509293320981]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_4 = classifier_4.evaluate(train_x, train_y, batch_size=128)\n",
    "score_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  54.27509293320981\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score_4[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does it effect the accuracy?\n",
    "**Ans:** As we can see, I have used 2 cost functions named Squared_Hinge and Hinge, the accuracy of each is 84.58 and 54.27 respectively. Squared_Hinge is better than Hinge.\n",
    "\n",
    "##### How does it effect how quickly the network plateaus?\n",
    "**Ans:** For Squared_Hinge, the loss is not reducing much so the network plateaus is acheivable if we increase epochs. For Hinge the network plateau is acheived at the second epoch itself since the loss and accuracy remains same after epoch 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D: Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"one\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.8193 - acc: 0.6330\n",
      "Epoch 2/20\n",
      "19906/19906 [==============================] - 50s 2ms/step - loss: 0.7125 - acc: 0.6903\n",
      "Epoch 3/20\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.6497 - acc: 0.7255\n",
      "Epoch 4/20\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.5983 - acc: 0.7468\n",
      "Epoch 5/20\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.5402 - acc: 0.7743\n",
      "Epoch 6/20\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.4890 - acc: 0.7989\n",
      "Epoch 7/20\n",
      "19906/19906 [==============================] - 50s 2ms/step - loss: 0.4319 - acc: 0.8233\n",
      "Epoch 8/20\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.3788 - acc: 0.8460\n",
      "Epoch 9/20\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.3238 - acc: 0.8714\n",
      "Epoch 10/20\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.2781 - acc: 0.8927\n",
      "Epoch 11/20\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.2361 - acc: 0.9087\n",
      "Epoch 12/20\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.2019 - acc: 0.9219\n",
      "Epoch 13/20\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.1681 - acc: 0.9373\n",
      "Epoch 14/20\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.1465 - acc: 0.9440\n",
      "Epoch 15/20\n",
      "19906/19906 [==============================] - 50s 2ms/step - loss: 0.1310 - acc: 0.9520\n",
      "Epoch 16/20\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.1194 - acc: 0.9567\n",
      "Epoch 17/20\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.1040 - acc: 0.9612\n",
      "Epoch 18/20\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.0939 - acc: 0.9650\n",
      "Epoch 19/20\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.0861 - acc: 0.9698\n",
      "Epoch 20/20\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.0793 - acc: 0.9724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b48a5cc2b0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_5 = Sequential()\n",
    "\n",
    "classifier_5.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))\n",
    "classifier_5.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_5.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer\n",
    "classifier_5.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_5.add(Flatten()) #Flattening the matrix\n",
    "classifier_5.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_5.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_5.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_5.add(Dense(output_dim = 3, activation = 'softmax'))\n",
    "act = keras.layers.advanced_activations.PReLU(init='one', weights=None)\n",
    "classifier_5.add(act)\n",
    "classifier_5.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "epochs = 20\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance\n",
    "classifier_5.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19906/19906 [==============================] - 17s 852us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.061956375702208015, 0.9790013061388526]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_5 = classifier_5.evaluate(train_x, train_y, batch_size=128)\n",
    "score_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  97.90013061388527\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score_5[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"one\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.8185 - acc: 0.6294\n",
      "Epoch 2/50\n",
      "19906/19906 [==============================] - 53s 3ms/step - loss: 0.7212 - acc: 0.6866\n",
      "Epoch 3/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.6643 - acc: 0.7129\n",
      "Epoch 4/50\n",
      "19906/19906 [==============================] - 60s 3ms/step - loss: 0.6053 - acc: 0.7418\n",
      "Epoch 5/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.5522 - acc: 0.7715\n",
      "Epoch 6/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.4980 - acc: 0.7920\n",
      "Epoch 7/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.4480 - acc: 0.8164\n",
      "Epoch 8/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.3963 - acc: 0.8394\n",
      "Epoch 9/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.3526 - acc: 0.8579\n",
      "Epoch 10/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.3082 - acc: 0.8789\n",
      "Epoch 11/50\n",
      "19906/19906 [==============================] - 63s 3ms/step - loss: 0.2700 - acc: 0.8947\n",
      "Epoch 12/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.2351 - acc: 0.9086\n",
      "Epoch 13/50\n",
      "19906/19906 [==============================] - 62s 3ms/step - loss: 0.2027 - acc: 0.9206\n",
      "Epoch 14/50\n",
      "19906/19906 [==============================] - 62s 3ms/step - loss: 0.1814 - acc: 0.9319\n",
      "Epoch 15/50\n",
      "19906/19906 [==============================] - 62s 3ms/step - loss: 0.1630 - acc: 0.9379\n",
      "Epoch 16/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.1360 - acc: 0.9481\n",
      "Epoch 17/50\n",
      "19906/19906 [==============================] - 63s 3ms/step - loss: 0.1308 - acc: 0.9502\n",
      "Epoch 18/50\n",
      "19906/19906 [==============================] - 63s 3ms/step - loss: 0.1090 - acc: 0.9594\n",
      "Epoch 19/50\n",
      "19906/19906 [==============================] - 64s 3ms/step - loss: 0.1103 - acc: 0.9591\n",
      "Epoch 20/50\n",
      "19906/19906 [==============================] - 60s 3ms/step - loss: 0.0993 - acc: 0.9630\n",
      "Epoch 21/50\n",
      "19906/19906 [==============================] - 63s 3ms/step - loss: 0.0855 - acc: 0.9684\n",
      "Epoch 22/50\n",
      "19906/19906 [==============================] - 63s 3ms/step - loss: 0.0865 - acc: 0.9700\n",
      "Epoch 23/50\n",
      "19906/19906 [==============================] - 62s 3ms/step - loss: 0.0846 - acc: 0.9704\n",
      "Epoch 24/50\n",
      "19906/19906 [==============================] - 60s 3ms/step - loss: 0.0654 - acc: 0.9775\n",
      "Epoch 25/50\n",
      "19906/19906 [==============================] - 63s 3ms/step - loss: 0.0766 - acc: 0.9737\n",
      "Epoch 26/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.0612 - acc: 0.9780\n",
      "Epoch 27/50\n",
      "19906/19906 [==============================] - 59s 3ms/step - loss: 0.0653 - acc: 0.9771\n",
      "Epoch 28/50\n",
      "19906/19906 [==============================] - 58s 3ms/step - loss: 0.0607 - acc: 0.9791\n",
      "Epoch 29/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.0593 - acc: 0.9796\n",
      "Epoch 30/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.0583 - acc: 0.9791\n",
      "Epoch 31/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.0493 - acc: 0.9823\n",
      "Epoch 32/50\n",
      "19906/19906 [==============================] - 62s 3ms/step - loss: 0.0490 - acc: 0.9833\n",
      "Epoch 33/50\n",
      "19906/19906 [==============================] - 62s 3ms/step - loss: 0.0505 - acc: 0.9819\n",
      "Epoch 34/50\n",
      "19906/19906 [==============================] - 60s 3ms/step - loss: 0.0461 - acc: 0.9843\n",
      "Epoch 35/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.0460 - acc: 0.9846\n",
      "Epoch 36/50\n",
      "19906/19906 [==============================] - 60s 3ms/step - loss: 0.0434 - acc: 0.9859\n",
      "Epoch 37/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.0385 - acc: 0.9863\n",
      "Epoch 38/50\n",
      "19906/19906 [==============================] - 59s 3ms/step - loss: 0.0447 - acc: 0.9846\n",
      "Epoch 39/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.0495 - acc: 0.9853\n",
      "Epoch 40/50\n",
      "19906/19906 [==============================] - 59s 3ms/step - loss: 0.0412 - acc: 0.9862\n",
      "Epoch 41/50\n",
      "19906/19906 [==============================] - 62s 3ms/step - loss: 0.0359 - acc: 0.9869\n",
      "Epoch 42/50\n",
      "19906/19906 [==============================] - 59s 3ms/step - loss: 0.0383 - acc: 0.9878\n",
      "Epoch 43/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.0386 - acc: 0.9861\n",
      "Epoch 44/50\n",
      "19906/19906 [==============================] - 62s 3ms/step - loss: 0.0336 - acc: 0.9886\n",
      "Epoch 45/50\n",
      "19906/19906 [==============================] - 62s 3ms/step - loss: 0.0367 - acc: 0.9873\n",
      "Epoch 46/50\n",
      "19906/19906 [==============================] - 62s 3ms/step - loss: 0.0408 - acc: 0.9865\n",
      "Epoch 47/50\n",
      "19906/19906 [==============================] - 64s 3ms/step - loss: 0.0349 - acc: 0.9883\n",
      "Epoch 48/50\n",
      "19906/19906 [==============================] - 65s 3ms/step - loss: 0.0277 - acc: 0.9906\n",
      "Epoch 49/50\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.0389 - acc: 0.9871\n",
      "Epoch 50/50\n",
      "19906/19906 [==============================] - 62s 3ms/step - loss: 0.0351 - acc: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b48b26ac88>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_6 = Sequential()\n",
    "\n",
    "classifier_6.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))\n",
    "classifier_6.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_6.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer\n",
    "classifier_6.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_6.add(Flatten()) #Flattening the matrix\n",
    "classifier_6.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_6.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_6.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_6.add(Dense(output_dim = 3, activation = 'softmax'))\n",
    "act = keras.layers.advanced_activations.PReLU(init='one', weights=None)\n",
    "classifier_6.add(act)\n",
    "classifier_6.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "epochs = 50\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance\n",
    "classifier_6.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19906/19906 [==============================] - 17s 873us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.016029941555547524, 0.9949763890284337]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_6 = classifier_6.evaluate(train_x, train_y, batch_size=128)\n",
    "score_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  99.49763890284336\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score_6[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does it effect the accuracy?\n",
    "**Ans:** As we can see, I have used 2 epochs 20 and 50, the accuracy of each is 97% and 99% respectively. It is obvious that as the epochs increases accuracy increases.\n",
    "\n",
    "##### How does it effect how quickly the network plateaus?\n",
    "**Ans:** Network Plateau is almost acheived at epoch 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E: Gradient Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"one\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.8223 - acc: 0.6312\n",
      "Epoch 2/30\n",
      "19906/19906 [==============================] - 59s 3ms/step - loss: 0.7089 - acc: 0.6951\n",
      "Epoch 3/30\n",
      "19906/19906 [==============================] - 60s 3ms/step - loss: 0.6513 - acc: 0.7283\n",
      "Epoch 4/30\n",
      "19906/19906 [==============================] - 59s 3ms/step - loss: 0.6062 - acc: 0.7489\n",
      "Epoch 5/30\n",
      "19906/19906 [==============================] - 59s 3ms/step - loss: 0.5729 - acc: 0.7692\n",
      "Epoch 6/30\n",
      "19906/19906 [==============================] - 60s 3ms/step - loss: 0.5374 - acc: 0.7860\n",
      "Epoch 7/30\n",
      "19906/19906 [==============================] - 59s 3ms/step - loss: 0.5041 - acc: 0.8005\n",
      "Epoch 8/30\n",
      "19906/19906 [==============================] - 62s 3ms/step - loss: 0.4922 - acc: 0.8073\n",
      "Epoch 9/30\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.4715 - acc: 0.8221\n",
      "Epoch 10/30\n",
      "19906/19906 [==============================] - 61s 3ms/step - loss: 0.4705 - acc: 0.8274\n",
      "Epoch 11/30\n",
      "19906/19906 [==============================] - 59s 3ms/step - loss: 0.4467 - acc: 0.8297\n",
      "Epoch 12/30\n",
      "19906/19906 [==============================] - 63s 3ms/step - loss: 0.4516 - acc: 0.8314\n",
      "Epoch 13/30\n",
      "19906/19906 [==============================] - 67s 3ms/step - loss: 0.4519 - acc: 0.8338\n",
      "Epoch 14/30\n",
      "19906/19906 [==============================] - 68s 3ms/step - loss: 0.4460 - acc: 0.8411\n",
      "Epoch 15/30\n",
      "19906/19906 [==============================] - 69s 3ms/step - loss: 0.4451 - acc: 0.8410\n",
      "Epoch 16/30\n",
      "19906/19906 [==============================] - 68s 3ms/step - loss: 0.4306 - acc: 0.8465\n",
      "Epoch 17/30\n",
      "19906/19906 [==============================] - 69s 3ms/step - loss: 0.4327 - acc: 0.8458\n",
      "Epoch 18/30\n",
      "19906/19906 [==============================] - 67s 3ms/step - loss: 0.4390 - acc: 0.8460\n",
      "Epoch 19/30\n",
      "19906/19906 [==============================] - 69s 3ms/step - loss: 0.4488 - acc: 0.8443\n",
      "Epoch 20/30\n",
      "19906/19906 [==============================] - 68s 3ms/step - loss: 0.4299 - acc: 0.8482\n",
      "Epoch 21/30\n",
      "19906/19906 [==============================] - 64s 3ms/step - loss: 0.4329 - acc: 0.8510\n",
      "Epoch 22/30\n",
      "19906/19906 [==============================] - 63s 3ms/step - loss: 0.4503 - acc: 0.8458\n",
      "Epoch 23/30\n",
      "19906/19906 [==============================] - 64s 3ms/step - loss: 0.4171 - acc: 0.8543\n",
      "Epoch 24/30\n",
      "19906/19906 [==============================] - 65s 3ms/step - loss: 0.4037 - acc: 0.8574\n",
      "Epoch 25/30\n",
      "19906/19906 [==============================] - 65s 3ms/step - loss: 0.4340 - acc: 0.8563\n",
      "Epoch 26/30\n",
      "19906/19906 [==============================] - 65s 3ms/step - loss: 0.4233 - acc: 0.8561\n",
      "Epoch 27/30\n",
      "19906/19906 [==============================] - 65s 3ms/step - loss: 0.4245 - acc: 0.8512\n",
      "Epoch 28/30\n",
      "19906/19906 [==============================] - 64s 3ms/step - loss: 0.4200 - acc: 0.8572\n",
      "Epoch 29/30\n",
      "19906/19906 [==============================] - 64s 3ms/step - loss: 0.4201 - acc: 0.8573\n",
      "Epoch 30/30\n",
      "19906/19906 [==============================] - 64s 3ms/step - loss: 0.3980 - acc: 0.8659\n",
      "19906/19906 [==============================] - 18s 925us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8190829288261231, 0.5427509293320981]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_7 = Sequential()\n",
    "\n",
    "classifier_7.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))\n",
    "classifier_7.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_7.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer\n",
    "classifier_7.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_7.add(Flatten()) #Flattening the matrix\n",
    "classifier_7.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_7.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_7.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_7.add(Dense(output_dim = 3, activation = 'softmax'))\n",
    "act = keras.layers.advanced_activations.PReLU(init='one', weights=None)\n",
    "classifier_7.add(act)\n",
    "classifier_7.compile(optimizer = 'RMSProp',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "epochs = 30\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance\n",
    "classifier_7.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)\n",
    "\n",
    "score_7 = classifier_4.evaluate(train_x, train_y, batch_size=128)\n",
    "score_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19906/19906 [==============================] - 19s 930us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40898967486619353, 0.863357781603338]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_7 = classifier_7.evaluate(train_x, train_y, batch_size=128)\n",
    "score_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  86.3357781603338\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score_7[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Stochastic Gradient Descent(SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19906/19906 [==============================] - 58s 3ms/step - loss: 0.9434 - acc: 0.5437\n",
      "Epoch 2/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.9040 - acc: 0.5628\n",
      "Epoch 3/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.8472 - acc: 0.6078\n",
      "Epoch 4/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.7910 - acc: 0.6440\n",
      "Epoch 5/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.7601 - acc: 0.6615\n",
      "Epoch 6/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.7392 - acc: 0.6762\n",
      "Epoch 7/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.7179 - acc: 0.6838\n",
      "Epoch 8/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.6976 - acc: 0.6954\n",
      "Epoch 9/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.6768 - acc: 0.7061\n",
      "Epoch 10/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.6597 - acc: 0.7134\n",
      "Epoch 11/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.6396 - acc: 0.7260\n",
      "Epoch 12/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.6187 - acc: 0.7383\n",
      "Epoch 13/30\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.6027 - acc: 0.7419\n",
      "Epoch 14/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.5794 - acc: 0.7566\n",
      "Epoch 15/30\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.5573 - acc: 0.7698\n",
      "Epoch 16/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.5359 - acc: 0.7777\n",
      "Epoch 17/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.5140 - acc: 0.7880\n",
      "Epoch 18/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.4925 - acc: 0.7996\n",
      "Epoch 19/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.4659 - acc: 0.8102\n",
      "Epoch 20/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.4396 - acc: 0.8244\n",
      "Epoch 21/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.4146 - acc: 0.8336\n",
      "Epoch 22/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.3875 - acc: 0.8460\n",
      "Epoch 23/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.3631 - acc: 0.8548\n",
      "Epoch 24/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.3406 - acc: 0.8682\n",
      "Epoch 25/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.3111 - acc: 0.8778\n",
      "Epoch 26/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.2803 - acc: 0.8938\n",
      "Epoch 27/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.2598 - acc: 0.8982\n",
      "Epoch 28/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.2346 - acc: 0.9111\n",
      "Epoch 29/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.2146 - acc: 0.9174\n",
      "Epoch 30/30\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.1873 - acc: 0.9311\n",
      "19906/19906 [==============================] - 15s 747us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1616879688020233, 0.9403697377076212]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_8 = Sequential()\n",
    "\n",
    "classifier_8.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))\n",
    "classifier_8.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_8.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer\n",
    "classifier_8.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_8.add(Flatten()) #Flattening the matrix\n",
    "classifier_8.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_8.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_8.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_8.add(Dense(output_dim = 3, activation = 'softmax'))\n",
    "# act = keras.layers.advanced_activations.PReLU(init='one', weights=None)\n",
    "# classifier_8.add(act)\n",
    "classifier_8.compile(optimizer = 'SGD',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "epochs = 30\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance\n",
    "classifier_8.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)\n",
    "\n",
    "score_8 = classifier_8.evaluate(train_x, train_y, batch_size=128)\n",
    "score_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  94.03697377076212\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score_8[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does it effect the accuracy?\n",
    "**Ans:** As we can see, I have used 2 gradient estimators RMSProp and SGD, the accuracy of each is 86% and 94% respectively. SGD is providing better accuracy.\n",
    "\n",
    "##### How does it effect how quickly the network plateaus?\n",
    "**Ans:** Network Plateau is almost acheived at epoch 30 in RMSProp while in SGD it needs more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part F: Network Architechture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.8446 - acc: 0.6204\n",
      "Epoch 2/30\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.7227 - acc: 0.6853\n",
      "Epoch 3/30\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.6587 - acc: 0.7187: 1s - loss: 0.\n",
      "Epoch 4/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.5942 - acc: 0.7524\n",
      "Epoch 5/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.5424 - acc: 0.7768\n",
      "Epoch 6/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.4869 - acc: 0.7997\n",
      "Epoch 7/30\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.4336 - acc: 0.8253\n",
      "Epoch 8/30\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.3823 - acc: 0.8469\n",
      "Epoch 9/30\n",
      "19906/19906 [==============================] - 53s 3ms/step - loss: 0.3349 - acc: 0.8694\n",
      "Epoch 10/30\n",
      "19906/19906 [==============================] - 50s 2ms/step - loss: 0.3006 - acc: 0.8827\n",
      "Epoch 11/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.2589 - acc: 0.9005\n",
      "Epoch 12/30\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.2307 - acc: 0.9093\n",
      "Epoch 13/30\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.2012 - acc: 0.9259\n",
      "Epoch 14/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.1797 - acc: 0.9326\n",
      "Epoch 15/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.1573 - acc: 0.9415\n",
      "Epoch 16/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.1418 - acc: 0.9456\n",
      "Epoch 17/30\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.1234 - acc: 0.9553\n",
      "Epoch 18/30\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.1115 - acc: 0.9597\n",
      "Epoch 19/30\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.1063 - acc: 0.9612\n",
      "Epoch 20/30\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.1001 - acc: 0.9642\n",
      "Epoch 21/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.0896 - acc: 0.9692\n",
      "Epoch 22/30\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.0784 - acc: 0.9712\n",
      "Epoch 23/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.0870 - acc: 0.9696\n",
      "Epoch 24/30\n",
      "19906/19906 [==============================] - 52s 3ms/step - loss: 0.0722 - acc: 0.9743\n",
      "Epoch 25/30\n",
      "19906/19906 [==============================] - 50s 2ms/step - loss: 0.0720 - acc: 0.9737\n",
      "Epoch 26/30\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.0656 - acc: 0.9771\n",
      "Epoch 27/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.0690 - acc: 0.9762\n",
      "Epoch 28/30\n",
      "19906/19906 [==============================] - 53s 3ms/step - loss: 0.0564 - acc: 0.9809\n",
      "Epoch 29/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.0605 - acc: 0.9799\n",
      "Epoch 30/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.0527 - acc: 0.9819\n",
      "19906/19906 [==============================] - 15s 745us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.048406088718556645, 0.9824675977571423]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_9 = Sequential()\n",
    "\n",
    "classifier_9.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))\n",
    "classifier_9.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_9.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer\n",
    "classifier_9.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_9.add(Flatten()) #Flattening the matrix\n",
    "classifier_9.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_9.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_9.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_9.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_9.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier_9.add(Dense(output_dim = 3, activation = 'softmax'))\n",
    "act = keras.layers.advanced_activations.PReLU(init='one', weights=None)\n",
    "classifier_9.add(act)\n",
    "classifier_9.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "epochs = 30\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance\n",
    "classifier_9.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)\n",
    "\n",
    "score_9 = classifier_9.evaluate(train_x, train_y, batch_size=128)\n",
    "score_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  98.24675977571424\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score_9[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of the Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.8303 - acc: 0.6226\n",
      "Epoch 2/30\n",
      "19906/19906 [==============================] - 40s 2ms/step - loss: 0.7133 - acc: 0.6875\n",
      "Epoch 3/30\n",
      "19906/19906 [==============================] - 40s 2ms/step - loss: 0.6559 - acc: 0.7173\n",
      "Epoch 4/30\n",
      "19906/19906 [==============================] - 40s 2ms/step - loss: 0.6054 - acc: 0.7425\n",
      "Epoch 5/30\n",
      "19906/19906 [==============================] - 40s 2ms/step - loss: 0.5589 - acc: 0.7675\n",
      "Epoch 6/30\n",
      "19906/19906 [==============================] - 41s 2ms/step - loss: 0.5164 - acc: 0.7877\n",
      "Epoch 7/30\n",
      "19906/19906 [==============================] - 42s 2ms/step - loss: 0.4735 - acc: 0.8072\n",
      "Epoch 8/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.4343 - acc: 0.8264\n",
      "Epoch 9/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.3958 - acc: 0.8431\n",
      "Epoch 10/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.3653 - acc: 0.8531\n",
      "Epoch 11/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.3334 - acc: 0.8688\n",
      "Epoch 12/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.3020 - acc: 0.8790\n",
      "Epoch 13/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.2757 - acc: 0.8935\n",
      "Epoch 14/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.2490 - acc: 0.9021\n",
      "Epoch 15/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.2283 - acc: 0.9107\n",
      "Epoch 16/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.2111 - acc: 0.9186\n",
      "Epoch 17/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.1870 - acc: 0.9279\n",
      "Epoch 18/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.1726 - acc: 0.9342\n",
      "Epoch 19/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.1578 - acc: 0.9400\n",
      "Epoch 20/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.1449 - acc: 0.9467\n",
      "Epoch 21/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.1371 - acc: 0.9499\n",
      "Epoch 22/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.1220 - acc: 0.9534\n",
      "Epoch 23/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.1184 - acc: 0.9561\n",
      "Epoch 24/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.1113 - acc: 0.9573\n",
      "Epoch 25/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.0984 - acc: 0.9637\n",
      "Epoch 26/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.0891 - acc: 0.9676\n",
      "Epoch 27/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.0933 - acc: 0.9665\n",
      "Epoch 28/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.0862 - acc: 0.9692\n",
      "Epoch 29/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.0809 - acc: 0.9701\n",
      "Epoch 30/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.0676 - acc: 0.9768\n",
      "19906/19906 [==============================] - 14s 709us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06851508052555338, 0.9758364312746747]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_10 = Sequential()\n",
    "\n",
    "classifier_10.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))\n",
    "classifier_10.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_10.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer\n",
    "classifier_10.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_10.add(Flatten()) #Flattening the matrix\n",
    "classifier_10.add(Dense(output_dim = 64, activation = 'relu'))\n",
    "classifier_10.add(Dense(output_dim = 64, activation = 'relu'))\n",
    "classifier_10.add(Dense(output_dim = 64, activation = 'relu'))\n",
    "classifier_10.add(Dense(output_dim = 3, activation = 'softmax'))\n",
    "# act = keras.layers.advanced_activations.PReLU(init='one', weights=None)\n",
    "# classifier_10.add(act)\n",
    "classifier_10.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "epochs = 30\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance\n",
    "classifier_10.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)\n",
    "\n",
    "score_10 = classifier_10.evaluate(train_x, train_y, batch_size=128)\n",
    "score_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  97.58364312746747\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score_10[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does it effect the accuracy?\n",
    "**Ans:** As we can see, I have change number of layers and size of the layer, the accuracy of each is 98% and 97% respectively. We can see that as we add a layer, the accuracy increases.\n",
    "\n",
    "##### How does it effect how quickly the network plateaus?\n",
    "**Ans:** Network Plateau is not acheived till 30 epochs in both the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part G: Network initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"glorot_normal\", activation=\"relu\", units=64)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"glorot_normal\", activation=\"relu\", units=64)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"glorot_normal\", activation=\"relu\", units=64)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"glorot_normal\", activation=\"softmax\", units=3)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.8287 - acc: 0.6244\n",
      "Epoch 2/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.7055 - acc: 0.6931\n",
      "Epoch 3/30\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.6489 - acc: 0.7232\n",
      "Epoch 4/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.6020 - acc: 0.7417\n",
      "Epoch 5/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.5655 - acc: 0.7611\n",
      "Epoch 6/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.5232 - acc: 0.7791\n",
      "Epoch 7/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.4815 - acc: 0.8034\n",
      "Epoch 8/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.4515 - acc: 0.8159\n",
      "Epoch 9/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.4125 - acc: 0.8301\n",
      "Epoch 10/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.3830 - acc: 0.8443\n",
      "Epoch 11/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.3527 - acc: 0.8583\n",
      "Epoch 12/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.3238 - acc: 0.8697\n",
      "Epoch 13/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.2867 - acc: 0.8887\n",
      "Epoch 14/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.2694 - acc: 0.8922\n",
      "Epoch 15/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.2487 - acc: 0.9005\n",
      "Epoch 16/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.2251 - acc: 0.9103\n",
      "Epoch 17/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.2032 - acc: 0.9199\n",
      "Epoch 18/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.1907 - acc: 0.9261\n",
      "Epoch 19/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.1695 - acc: 0.9347\n",
      "Epoch 20/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.1552 - acc: 0.9400\n",
      "Epoch 21/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.1489 - acc: 0.9438\n",
      "Epoch 22/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.1369 - acc: 0.9465\n",
      "Epoch 23/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.1306 - acc: 0.9507\n",
      "Epoch 24/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.1150 - acc: 0.9574\n",
      "Epoch 25/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.1127 - acc: 0.9574\n",
      "Epoch 26/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.1090 - acc: 0.9589\n",
      "Epoch 27/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.1019 - acc: 0.9624\n",
      "Epoch 28/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.0953 - acc: 0.9655\n",
      "Epoch 29/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.0938 - acc: 0.9656\n",
      "Epoch 30/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.0906 - acc: 0.9673\n",
      "19906/19906 [==============================] - 14s 725us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1585465131270805, 0.9474530293332336]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_11 = Sequential()\n",
    "\n",
    "classifier_11.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))\n",
    "classifier_11.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_11.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer\n",
    "classifier_11.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_11.add(Flatten()) #Flattening the matrix\n",
    "classifier_11.add(Dense(output_dim = 64, kernel_initializer=\"glorot_normal\", activation = 'relu'))\n",
    "classifier_11.add(Dense(output_dim = 64, kernel_initializer=\"glorot_normal\", activation = 'relu'))\n",
    "classifier_11.add(Dense(output_dim = 64, kernel_initializer=\"glorot_normal\", activation = 'relu'))\n",
    "classifier_11.add(Dense(output_dim = 3, kernel_initializer=\"glorot_normal\", activation = 'softmax'))\n",
    "# act = keras.layers.advanced_activations.PReLU(init='one', weights=None)\n",
    "# classifier_11.add(act)\n",
    "classifier_11.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "epochs = 30\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance\n",
    "classifier_11.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)\n",
    "\n",
    "score_11 = classifier_11.evaluate(train_x, train_y, batch_size=128)\n",
    "score_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  97.01597508229072\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score_11[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Xavier Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"glorot_uniform\", activation=\"relu\", units=64)`\n",
      "  \n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"glorot_uniform\", activation=\"relu\", units=64)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"glorot_uniform\", activation=\"relu\", units=64)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"glorot_uniform\", activation=\"softmax\", units=3)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.8261 - acc: 0.6221\n",
      "Epoch 2/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.7137 - acc: 0.6867\n",
      "Epoch 3/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.6544 - acc: 0.7157\n",
      "Epoch 4/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.6072 - acc: 0.7361\n",
      "Epoch 5/30\n",
      "19906/19906 [==============================] - 43s 2ms/step - loss: 0.5578 - acc: 0.7626\n",
      "Epoch 6/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.5099 - acc: 0.7871\n",
      "Epoch 7/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.4653 - acc: 0.8046\n",
      "Epoch 8/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.4302 - acc: 0.8249\n",
      "Epoch 9/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.3959 - acc: 0.8387\n",
      "Epoch 10/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.3602 - acc: 0.8532\n",
      "Epoch 11/30\n",
      "19906/19906 [==============================] - 44s 2ms/step - loss: 0.3258 - acc: 0.8702\n",
      "Epoch 12/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.2969 - acc: 0.8803\n",
      "Epoch 13/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.2772 - acc: 0.8883\n",
      "Epoch 14/30\n",
      "19906/19906 [==============================] - 46s 2ms/step - loss: 0.2432 - acc: 0.9005\n",
      "Epoch 15/30\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.2262 - acc: 0.9102\n",
      "Epoch 16/30\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.2015 - acc: 0.9217\n",
      "Epoch 17/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.1824 - acc: 0.9298\n",
      "Epoch 18/30\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.1741 - acc: 0.9330\n",
      "Epoch 19/30\n",
      "19906/19906 [==============================] - 51s 3ms/step - loss: 0.1600 - acc: 0.9376\n",
      "Epoch 20/30\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.1449 - acc: 0.9458\n",
      "Epoch 21/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.1391 - acc: 0.9487\n",
      "Epoch 22/30\n",
      "19906/19906 [==============================] - 45s 2ms/step - loss: 0.1257 - acc: 0.9534\n",
      "Epoch 23/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.1181 - acc: 0.9561\n",
      "Epoch 24/30\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.1137 - acc: 0.9588\n",
      "Epoch 25/30\n",
      "19906/19906 [==============================] - 47s 2ms/step - loss: 0.1026 - acc: 0.9617\n",
      "Epoch 26/30\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.0984 - acc: 0.9638\n",
      "Epoch 27/30\n",
      "19906/19906 [==============================] - 49s 2ms/step - loss: 0.0899 - acc: 0.9672\n",
      "Epoch 28/30\n",
      "19906/19906 [==============================] - 52s 3ms/step - loss: 0.0914 - acc: 0.9661\n",
      "Epoch 29/30\n",
      "19906/19906 [==============================] - 50s 3ms/step - loss: 0.0837 - acc: 0.9699\n",
      "Epoch 30/30\n",
      "19906/19906 [==============================] - 48s 2ms/step - loss: 0.0831 - acc: 0.9708\n",
      "19906/19906 [==============================] - 15s 736us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08590449643269216, 0.9701597508229072]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_11 = Sequential()\n",
    "\n",
    "classifier_11.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu'))\n",
    "classifier_11.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_11.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer\n",
    "classifier_11.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix\n",
    "classifier_11.add(Flatten()) #Flattening the matrix\n",
    "classifier_11.add(Dense(output_dim = 64, kernel_initializer=\"glorot_uniform\", activation = 'relu'))\n",
    "classifier_11.add(Dense(output_dim = 64, kernel_initializer=\"glorot_uniform\", activation = 'relu'))\n",
    "classifier_11.add(Dense(output_dim = 64, kernel_initializer=\"glorot_uniform\", activation = 'relu'))\n",
    "classifier_11.add(Dense(output_dim = 3, kernel_initializer=\"glorot_uniform\", activation = 'softmax'))\n",
    "# act = keras.layers.advanced_activations.PReLU(init='one', weights=None)\n",
    "# classifier_11.add(act)\n",
    "classifier_11.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "epochs = 30\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance\n",
    "classifier_11.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)\n",
    "\n",
    "score_11 = classifier_11.evaluate(train_x, train_y, batch_size=128)\n",
    "score_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  97.01597508229072\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (score_11[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does it effect the accuracy?\n",
    "**Ans:** As we can see, I have used 2 network initializers Gaussian and Xavier Uniform, the accuracy of each is 94% and 97% respectively. We can see that as we add a layer, the accuracy increases.\n",
    "\n",
    "##### How does it effect how quickly the network plateaus?\n",
    "**Ans:** Network Plateau is not acheived till 30 epochs in both the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refernces:\n",
    "\n",
    "- https://www.kaggle.com/ashishpatel26/indian-movie-face-database-imfdm-keras\n",
    "- https://github.com/smartyining/IMFDB\n",
    "- https://machinelearningmastery.com/improve-deep-learning-performance/\n",
    "- https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
